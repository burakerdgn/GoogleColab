{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_deneme_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JBbcGF8-7YGc",
        "t7ysqwBWI2Ch",
        "_IRaFagmg3gU",
        "Lb_JOIQEBEud",
        "caqsxHkcGlLR",
        "fwwcnXLUrvS6"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOGHBx+GSrgCLdEvYTXDvpi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burakerdgn/GoogleColab/blob/main/keras_deneme_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXjWz9Zt7BcF"
      },
      "source": [
        "## ***Connection to Google Drive***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tWTaxd6Uc2Q",
        "outputId": "75f5f0cc-ca64-42c9-b8fc-d51bec7060ff"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 160983 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UQw8XSFUuDk"
      },
      "source": [
        "!mkdir -p drive\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mfrLPu6Q3K2"
      },
      "source": [
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buh6cOXvU5GR"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'drive/Colab_workspace')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLYiN3h7U9vP",
        "outputId": "2759af72-1d77-4fc1-ff95-6e7248f19384"
      },
      "source": [
        "cd drive/Colab_workspace/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Colab_workspace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJll6QfzbO8C"
      },
      "source": [
        "!pip install -q keras\n",
        "import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Op2-JL6vUOU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJIyv4uEBvjX",
        "outputId": "dd007988-1e70-4fb5-ade9-c0a2b3ea3b05"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA\t\t      ngrok-stable-linux-amd64.zip\n",
            "keras_deneme1.ipynb   pratik-derin-ogrenme-uygulamalari\n",
            "keras_deneme_2.ipynb  rakam_tanima_CNN_MNIST_Keras.py\n",
            "keras-mnist-tutorial  tb_logs\n",
            "ngrok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBbcGF8-7YGc"
      },
      "source": [
        "## ***Bank Data Project***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm9ch1WNbYUd"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "data = genfromtxt('DATA/bank_note_data.txt',delimiter=',')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_jZabkv_J0"
      },
      "source": [
        "labels = data[:,4]\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QFTkXf0yawz"
      },
      "source": [
        "features = data [:,0:4]\n",
        "features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpzbilO0yppH"
      },
      "source": [
        "X = features\n",
        "y = labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k49KB7e1ywRG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jRgCrwuy83q"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_G7623-1Tvk"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QGUFtQa1kfI"
      },
      "source": [
        "scaler_object = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jlMfPEp1uoW"
      },
      "source": [
        "scaler_object.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Q-MYk_2CXb"
      },
      "source": [
        "scaled_X_train = scaler_object.transform(X_train)\n",
        "scaled_X_test = scaler_object.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrhcXSCv2jL-"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6U2hOy6290v"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4,input_dim=4,activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTp85z_n3LdC"
      },
      "source": [
        "model.add(Dense(8,activation='relu'))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg_E_pSB3uN4"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyV2a3oG4Cdw"
      },
      "source": [
        "model.fit(scaled_X_train,y_train,epochs=50,verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk_L-Kfh4a9j"
      },
      "source": [
        " abc = model.predict_classes(scaled_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMjBiBaK4nXT"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91krU6gn4wDm"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA-Xz7yi47v3"
      },
      "source": [
        "confusion_matrix(y_test,model.predict_classes(scaled_X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7ysqwBWI2Ch"
      },
      "source": [
        "## ***KERAS CNN WITH MNIST***\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVc4n-pJJQb8"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v-9rucfJM1n"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9tRvKYvRtBY"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4oPsH-yZ-rt"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmxNG0wQTRNN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nScHamvVTzS2"
      },
      "source": [
        "single_image = x_train[0]\n",
        "plt.imshow(single_image,cmap='gray_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij8hxshoUisA"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xx9WnmJUlhG"
      },
      "source": [
        "from keras.utils.np_utils import  to_categorical\n",
        "\n",
        "y_cat_test = to_categorical(y_test,10)\n",
        "y_cat_train = to_categorical(y_train,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNOYCb-kaFPf"
      },
      "source": [
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "x_train.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ng84xdRaqgI"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_rOb0isaz31"
      },
      "source": [
        "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paPBbafJbDOk"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
        "\n",
        "# Pooling Layer\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten  2d --> 1d\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQJCNdnoeAUj"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mEn6-wlfGZs"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8E_ENGdek-W"
      },
      "source": [
        "model.fit(x_train,y_cat_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMb1M_Yqfmd4"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NmOyiBgfpsA"
      },
      "source": [
        "y_cat_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cal9D7eIfRE2"
      },
      "source": [
        "model.evaluate(x_test,y_cat_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FrP4mXkf0_z"
      },
      "source": [
        "from sklearn.metrics import  classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqaLC6ONgUKt"
      },
      "source": [
        "predictions = model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIWjUdSsga8b"
      },
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IRaFagmg3gU"
      },
      "source": [
        "## ***KERAS CNN WITH CIFAR-10***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3eKbcVbhiSe"
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr5_UrVih5Q6"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngr6Gu9QiL_y"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pchCbtiimn5V"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwjFFrPMmurf"
      },
      "source": [
        "plt.imshow(x_train[12005])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLvAoD6EnDiA"
      },
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9YAsrUynThZ"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpYhBAwnY83"
      },
      "source": [
        "y_cat_train = to_categorical(y_train,10)\n",
        "y_cat_test = to_categorical(y_test,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70CmTLpEnx4L"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu'))\n",
        "\n",
        "# Pooling Layer\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "# Repeat Convolutional and pooling layer\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten  2d --> 1d\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer (Neuron number muust be 2^x)\n",
        "\n",
        "model.add(Dense(256,activation='relu'))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-9SO5WMpic9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMpCHNDdppQ0"
      },
      "source": [
        "model.fit(x_train,y_cat_train,verbose=1,epochs=10,batch_size=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyddQoc3tZMj"
      },
      "source": [
        "model.evaluate(x_test,y_cat_test,batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfPiQAPSuPeT"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = model.predict_classes(x_test)\n",
        "\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb_JOIQEBEud"
      },
      "source": [
        "## ***Fashion MNIST Project***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S_z59PNCBNn"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbeeDPD2CAfF"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train,y_train),(x_test,y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIu0snbUCouA"
      },
      "source": [
        "**Visualize the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "vPF0xe8vBR2-",
        "outputId": "77d43202-de41-4c1e-e9d2-3284f1144eca"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "single_image = x_train[0]\n",
        "plt.imshow(single_image,cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4e482a71d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifcVS_QODaKl"
      },
      "source": [
        "**Preprocessing the Data (Normalize the X train and X test by dividing by the max value of the image arrays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCztgfCFDgeH"
      },
      "source": [
        "x_train = x_train/x_train.max()\n",
        "x_test = x_test/x_test.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwo0AQ9DFDls"
      },
      "source": [
        "**Add 4. dimension to X arrays**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLOMdCqnFC7s"
      },
      "source": [
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VMnXhpTGNXF"
      },
      "source": [
        "**Convert Y arrays into one-hot encoded for categorical analysis by Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvMpaO1yGa09"
      },
      "source": [
        "from keras.utils.np_utils import  to_categorical\n",
        "\n",
        "y_cat_test = to_categorical(y_test,10)\n",
        "y_cat_train = to_categorical(y_train,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caqsxHkcGlLR"
      },
      "source": [
        "### **Build the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNobWumOHCUp"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQeZpKc_HRAx"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# CONVOLUTIONAL LAYER\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
        "\n",
        "# Pooling Layer\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "# Flatten  2d --> 1d\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense Layer\n",
        "\n",
        "model.add(Dense(128,activation='relu'))   # 128 --> Neurons' number (optional for any value which is 2^x)\n",
        "\n",
        "model.add(Dense(10,activation='softmax')) # 10 --> (class number)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSQ--Rz3H4mZ",
        "outputId": "1a3c7657-aaf7-4654-d06c-0e8c98d2a719"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 591,786\n",
            "Trainable params: 591,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1_nwa4JISME"
      },
      "source": [
        "**Train the set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAojtyW8IBZd",
        "outputId": "d00166fd-0c16-4396-a3b4-2ffc91a2ca28"
      },
      "source": [
        "model.fit(x_train,y_cat_train,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5360 - accuracy: 0.8101\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2856 - accuracy: 0.8980\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2402 - accuracy: 0.9145\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2129 - accuracy: 0.9252\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1964 - accuracy: 0.9292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e4822cd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVwNmbgBIxwr",
        "outputId": "54a84733-6846-4996-a67c-92cef30ab710"
      },
      "source": [
        "model.evaluate(x_test,y_cat_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.9064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2718176245689392, 0.9064000248908997]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcI8N0KLJOmk",
        "outputId": "424c6017-20ef-4620-97e3-8778fb964b8b"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "predictions = model.predict_classes(x_test)\n",
        "\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.83      0.86      0.85      1000\n",
            "           3       0.95      0.87      0.91      1000\n",
            "           4       0.84      0.84      0.84      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.74      0.74      0.74      1000\n",
            "           7       0.95      0.98      0.96      1000\n",
            "           8       0.98      0.98      0.98      1000\n",
            "           9       0.97      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdnR01L7RMrK",
        "outputId": "61b871b4-f556-427d-f3e4-4fb3d086f555"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNLt6KgxJcY0",
        "outputId": "e7494dc3-34cd-4a03-ef32-ff69f3f0b737"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "one_image = x_test[6:2:2]\n",
        "one_image.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ddcvtAni2g"
      },
      "source": [
        "**Test Single Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "VJQ9TT9cZziB",
        "outputId": "ce4f87c4-4f13-471a-9dc5-e6716f277728"
      },
      "source": [
        "array1 =  x_test[8420,:,:,0]\n",
        "plt.imshow(array1,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4e45b4cc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARmElEQVR4nO3dbWyVZZoH8P8FFpHXlHZpQJAZXoIhki1rQ1TIqhl2FBIDo9EMMRM2GssHJhnMfNC4MeMXE7LZmdkx2UzsrGZgM4oTZyYiIWGQYBoSGUTToYiydQmFQmkBkcqbUHrthz6aon2u63Cec85z7PX/JaTlXL3PuTnw5znnXM/93KKqIKKRb1TeEyCiymDYiYJg2ImCYNiJgmDYiYK4qZIPJiL86L/CJk6caNZnzpxp1m+55RazfuLECbN+4cKF1Nro0aPNsd7ca2trzXp/f39qrbOz0xx7/vx5s17NVFWGuz1T2EXkQQC/ATAawH+r6oYs90el19TUZNZfeukls37HHXeY9eeff96s7927N7U2efJkc+yyZcvM+sMPP2zWT58+nVpbu3atOba1tdWsfxcV/TJeREYD+C8AywEsALBaRBaUamJEVFpZ3rMvBvCpqh5W1SsANgNYWZppEVGpZQn7rQCODfl9V3LbdUSkWUT2ici+DI9FRBmV/QM6VW0B0ALwAzqiPGU5sh8HMPSj3BnJbURUhbKE/X0A80Tk+yIyBsCPAWwpzbSIqNQky6o3EVkB4D8x2Hp7VVVfdH6eL+PLYOfOnam1RYsWmWOPHTtm1q9du2bWvfZZln715cuXzbrX4587d25qLev5BXPmzDHrXV1dZr2cytJnV9VtALZluQ8iqgyeLksUBMNOFATDThQEw04UBMNOFATDThREpj77DT8Y++xFWbdunVl/8cX00xv27NljjvXWlI8fP96s9/X1mfVTp06ZdcvAwIBZ93rhkyZNSq1duXLFHFtfX2/WOzo6zPqaNWvMejml9dl5ZCcKgmEnCoJhJwqCYScKgmEnCoJhJwqiopeSpuLcddddZv3MmTOptayXRPZaVN4yU6s1N3XqVHPsmDFjzPq5c+fM+qVLl4q+756eHrPe0NBg1qsRj+xEQTDsREEw7ERBMOxEQTDsREEw7ERBMOxEQbDPXqBRo9L/X/SWYnq8ZaTe5ZovXryYWps3b545dteuXWZ9xowZZt1jLTO15g345wh4l7m2/l5mz55tjvWec+/8gwUL7D1ODx48aNbLgUd2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiBGTJ/d6oMD2XvhWcY3NTWZ9dWrV5v106dPm/Xt27en1np7e82xZ8+eNeteP3nx4sVmvba2NrU2f/58c6zVowf8uVv1L7/80hz7+eefm3VvPfvChQvNeh599kxhF5EjAL4AcA1Av6ra/6qJKDelOLLfr6r2oYeIcsf37ERBZA27AviriHwgIs3D/YCINIvIPhHZl/GxiCiDrC/jl6rqcRGZCmCHiHyiqq1Df0BVWwC0ANzrjShPmY7sqno8+doL4C8A7I9miSg3RYddRMaLyMSvvgfwQwAHSjUxIiqtordsFpHZGDyaA4NvB15T1fS9gzFyX8Z7Wyrfe++9Zn3//v1m/fLly2bdWvd99epVc2xz87AftXxt06ZNZt07B8Di9aq9a7tnue68t93zuHHjzPqUKVPMunfd+SeeeMKsZ5G2ZXPR79lV9TCAfyx6RkRUUWy9EQXBsBMFwbATBcGwEwXBsBMFMWKWuJbb3LlzU2tea81rX82aNcuse5dMtlpM7e3t5thHHnnErI8dO9ase5eqttprHR0d5tjRo0ebdW98Y2Njas17zq2tpgHgnXfeMes7duww63ngkZ0oCIadKAiGnSgIhp0oCIadKAiGnSgIhp0oCPbZC2T1srdt22aO9Xrd3jLR+vp6s/7ee++l1h5//HFzrLdMdM6cOWb93XffNevW8lzvUtEXLlww6ydPnjTr1rbJ3nP+1FNPmfXvIh7ZiYJg2ImCYNiJgmDYiYJg2ImCYNiJgmDYiYJgn71ADzzwQGpt2bJl5tinn37arHd2dpr1trY2s2714R966CFz7J133mnWa2pqzLq35nzz5s2ptRkzZphjvcs9e6zLaGfdwvu7iEd2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIBh2oiDC9Nm965+//PLLZt26Brm3tXB/f79Z99arP/PMM2bdWi/vrdveu3evWffm9uijj5r1urq61Nprr71mjvW2qr7pJvufr7WV9ZUrV8yxI5F7ZBeRV0WkV0QODLltiojsEJGO5GtteadJRFkV8jL+9wAe/MZtzwLYqarzAOxMfk9EVcwNu6q2AvjsGzevBLAx+X4jgFUlnhcRlVix79kbVLU7+f4kgNQNvUSkGUBzkY9DRCWS+QM6VVURUaPeAqAFAKyfI6LyKrb11iMi0wAg+dpbuikRUTkUG/YtANYk368B8FZppkNE5eK+jBeR1wHcB6BeRLoA/ALABgB/FJEnAXQCeKyckyyFDRs2mHVvn/HDhw8X/djemm/vvrdv3170Y9fW2l1R79rt3twvXbpk1letSv/stru7O7UG+Nfj9/rw1vkH06dPN8eORG7YVXV1SukHJZ4LEZURT5clCoJhJwqCYScKgmEnCoJhJwoizBJXr7XmLQXt6OhIrc2cOdMc6y1x9bYm9tpf48ePT615SznPnj2bqe61v7Zu3ZpamzZtmjnWW1572223mfV77rkntXbt2jVz7EjEIztREAw7URAMO1EQDDtREAw7URAMO1EQDDtRECOmzz5r1iyz7vWqPdblok+cOFH0WADo6enJND7LZZGtbY0Lue+FCxeadetyzt6WzLNnzzbrK1asMOvWuRNZ/z18F/HIThQEw04UBMNOFATDThQEw04UBMNOFATDThTEiOmzL1++3Kx7lzw+dOiQWZ86dWpqzetVnzt3zqx7vLXXVt2bm9dv9nr8fX19Zt1aq+/12b1zJz755BOzbq3znzBhgjl2JOKRnSgIhp0oCIadKAiGnSgIhp0oCIadKAiGnSiIEdNnX7JkiVn3+sHWumsAqKurS6152x5711731ox7/Wirl+6dX+Ddt/dn855Xb8toy/z588360aNHzbp1joDVgx+p3CO7iLwqIr0icmDIbS+IyHERaUt+2VcRIKLcFfIy/vcAHhzm9l+ramPya1tpp0VEpeaGXVVbAXxWgbkQURll+YDupyKyP3mZn/rGTESaRWSfiOzL8FhElFGxYf8tgDkAGgF0A/hl2g+qaouqNqlqU5GPRUQlUFTYVbVHVa+p6gCA3wFYXNppEVGpFRV2ERm61+6PABxI+1kiqg5un11EXgdwH4B6EekC8AsA94lIIwAFcATA2jLOsSDr168363fffbdZv//++826tQe7d914r4c/efJks+6th7fWpHvr2b218mPHjjXr3rpw6zoAe/bsMcd65yd4+7tbfzbrmvIjlRt2VV09zM2vlGEuRFRGPF2WKAiGnSgIhp0oCIadKAiGnSiIEbPE9cyZM2Z969atmepvvvlmaq2mpsYcm9XAwECmepaxXmvt2LFjZv3tt99OrXntr9tvvz1T3fp7sS5xPVLxyE4UBMNOFATDThQEw04UBMNOFATDThQEw04UxIjps+fp4sWLZt3b9vjy5ctm3bsctHX/3pbM3mWsvSWw3hLa9vb21FpjY6M51lte653fkKXPPmqUfRzMcm5DXnhkJwqCYScKgmEnCoJhJwqCYScKgmEnCoJhJwqCffYCWevlvV60tz2wt+2xt62y1Yf3Htvrw3t1789ubfnsXQq6ra3NrL/xxhtmna7HIztREAw7URAMO1EQDDtREAw7URAMO1EQDDtREOyzF2j37t2ptaVLl5pjvbXTXi/c2/LZWpPuraXP2kf36tb9e2vCvevCHzp0yKzT9dwju4jMFJFdInJQRD4SkZ8lt08RkR0i0pF8rS3/dImoWIW8jO8H8HNVXQDgLgDrRGQBgGcB7FTVeQB2Jr8noirlhl1Vu1X1w+T7LwB8DOBWACsBbEx+bCOAVeWaJBFld0Pv2UXkewAWAfgbgAZV7U5KJwE0pIxpBtBc/BSJqBQK/jReRCYA+BOA9ap63coNVVUAOtw4VW1R1SZVbco0UyLKpKCwi0gNBoP+B1X9c3Jzj4hMS+rTAPSWZ4pEVAruy3gREQCvAPhYVX81pLQFwBoAG5Kvb5VlhlWitja92eBd8thrf2W5VLRX9+bmtc68uWVZIuvdt3eZa7oxhbxnXwLgJwDaReSrBcbPYTDkfxSRJwF0AnisPFMkolJww66quwFISvkHpZ0OEZULT5clCoJhJwqCYScKgmEnCoJhJwqCS1wLZPXZvT74uXPnzLp3qWhvS+f+/v7UmtdH9+7bG19fX2/Wx40bl1qbNWuWObazs9Os043hkZ0oCIadKAiGnSgIhp0oCIadKAiGnSgIhp0oCPbZCzR9+vTUmrfuOuvlmmtqasz6zTffbNYt3jkCV69eNeve3I8ePZpaa29vN8d2dXWZdboxPLITBcGwEwXBsBMFwbATBcGwEwXBsBMFwbATBcE+e4Hq6upSa319fak1wF+v7o33eH18i9fD9+retd+tP1tra6s5lkqLR3aiIBh2oiAYdqIgGHaiIBh2oiAYdqIgGHaiIArZn30mgE0AGgAogBZV/Y2IvADgKQCnkh99TlW3lWuinlGj7P+3BgYGMt2/1cu2rikPAN3d3Wbd61V7a8YtWXrwgP+8TZo0KdP9W8r9dxpNISfV9AP4uap+KCITAXwgIjuS2q9V9T/KNz0iKpVC9mfvBtCdfP+FiHwM4NZyT4yISuuG3rOLyPcALALwt+Smn4rIfhF5VUSGfS0rIs0isk9E9mWaKRFlUnDYRWQCgD8BWK+qfQB+C2AOgEYMHvl/Odw4VW1R1SZVbSrBfImoSAWFXURqMBj0P6jqnwFAVXtU9ZqqDgD4HYDF5ZsmEWXlhl1EBMArAD5W1V8NuX3akB/7EYADpZ8eEZVKIZ/GLwHwEwDtItKW3PYcgNUi0ojBdtwRAGvLMsMqYW1t7LW3vNaaJ88Wk9f+amhoKNtjs7VWWoV8Gr8bgAxTyq2nTkQ3jmfQEQXBsBMFwbATBcGwEwXBsBMFwbATBTFiLiVd7p7s2LFjU2vnz583x3pLVL1LSVuPDfi9cIs3N+8y2KdPny76samyeGQnCoJhJwqCYScKgmEnCoJhJwqCYScKgmEnCkJUtXIPJnIKQOeQm+oBVGujtlrnVq3zAji3YpVybrNU9R+GK1Q07N96cJF91XptumqdW7XOC+DcilWpufFlPFEQDDtREHmHvSXnx7dU69yqdV4A51asiswt1/fsRFQ5eR/ZiahCGHaiIHIJu4g8KCKHRORTEXk2jzmkEZEjItIuIm1570+X7KHXKyIHhtw2RUR2iEhH8tXeL7qyc3tBRI4nz12biKzIaW4zRWSXiBwUkY9E5GfJ7bk+d8a8KvK8Vfw9u4iMBvC/AP4FQBeA9wGsVtWDFZ1IChE5AqBJVXM/AUNE/hnAeQCbVPWO5LZ/B/CZqm5I/qOsVdVnqmRuLwA4n/c23sluRdOGbjMOYBWAf0WOz50xr8dQgectjyP7YgCfquphVb0CYDOAlTnMo+qpaiuAz75x80oAG5PvN2LwH0vFpcytKqhqt6p+mHz/BYCvthnP9bkz5lUReYT9VgDHhvy+C9W137sC+KuIfCAizXlPZhgNqtqdfH8SQPn2XyqOu413JX1jm/Gqee6K2f48K35A921LVfWfACwHsC55uVqVdPA9WDX1TgvaxrtShtlm/Gt5PnfFbn+eVR5hPw5g5pDfz0huqwqqejz52gvgL6i+rah7vtpBN/nam/N8vlZN23gPt804quC5y3P78zzC/j6AeSLyfREZA+DHALbkMI9vEZHxyQcnEJHxAH6I6tuKeguANcn3awC8leNcrlMt23inbTOOnJ+73Lc/V9WK/wKwAoOfyP8fgH/LYw4p85oN4O/Jr4/ynhuA1zH4su4qBj/beBJAHYCdADoAvANgShXN7X8AtAPYj8FgTctpbksx+BJ9P4C25NeKvJ87Y14Ved54uixREPyAjigIhp0oCIadKAiGnSgIhp0oCIadKAiGnSiI/wdFGtAPPPp5jwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6CZlLTymN2W",
        "outputId": "720b6617-9ed9-4759-b560-feab5073c695"
      },
      "source": [
        "array1 = np.expand_dims(array1,axis=(0,3))\n",
        "array1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx80pM1lmg1y",
        "outputId": "696deb69-9ba1-4b45-f7ec-acaf1e97ce9b"
      },
      "source": [
        "model.predict_classes(array1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwwcnXLUrvS6"
      },
      "source": [
        "# ***YOLO PROJECT***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL0sofUoR3xS",
        "outputId": "9d5529ff-90b0-4e9f-f8ac-97cc8c381bfa"
      },
      "source": [
        "cd DATA/06-YOLOv3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Colab_workspace/DATA/06-YOLOv3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhoyb2hsRW1S"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from model.yolo_model import YOLO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbIqX40LTRTV"
      },
      "source": [
        "def process_image(img):\n",
        "\n",
        "      image = cv2.resize(img, (416, 416),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "      image = np.array(image, dtype='float32')\n",
        "      image /= 255.\n",
        "      image = np.expand_dims(image, axis=0)\n",
        "      return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lNfBkQcUNeK"
      },
      "source": [
        "def get_classes(file):\n",
        "\n",
        "        with open(file) as f:\n",
        "           class_names = f.readlines()\n",
        "        class_names = [c.strip() for c in class_names]\n",
        "\n",
        "        return class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBoBD-gDUsMQ"
      },
      "source": [
        "def draw(image, boxes, scores, classes, all_classes):\n",
        "   \n",
        "        for box, score, cl in zip(boxes, scores, classes):\n",
        "            x, y, w, h = box\n",
        "   \n",
        "            top = max(0, np.floor(x + 0.5).astype(int))\n",
        "            left = max(0, np.floor(y + 0.5).astype(int))\n",
        "            right = min(image.shape[1], np.floor(x + w + 0.5).astype(int))\n",
        "            bottom = min(image.shape[0], np.floor(y + h + 0.5).astype(int))\n",
        "    \n",
        "            cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
        "            cv2.putText(image, '{0} {1:.2f}'.format(all_classes[cl], score),\n",
        "                       (top, left - 6),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.6, (0, 0, 255), 1,\n",
        "                        cv2.LINE_AA)\n",
        "    \n",
        "            print('class: {0}, score: {1:.2f}'.format(all_classes[cl], score))\n",
        "            print('box coordinate x,y,w,h: {0}'.format(box))\n",
        "    \n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Olxt2oVsK7"
      },
      "source": [
        "def detect_image(image, yolo, all_classes):\n",
        "   \n",
        "        pimage = process_image(image)\n",
        "  \n",
        "        start = time.time()\n",
        "        boxes, classes, scores = yolo.predict(pimage, image.shape)\n",
        "        end = time.time()\n",
        "   \n",
        "        print('time: {0:.2f}s'.format(end - start))\n",
        "    \n",
        "        if boxes is not None:\n",
        "            draw(image, boxes, scores, classes, all_classes)\n",
        "    \n",
        "        return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcT0TfF9WnJ3"
      },
      "source": [
        " def detect_video(video, yolo, all_classes):\n",
        " \n",
        "        video_path = os.path.join(\"videos\", \"test\", video)\n",
        "        camera = cv2.VideoCapture(video_path)\n",
        "        cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
        "  \n",
        "        # Prepare for saving the detected video\\n\",\n",
        "        sz = (int(camera.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "            int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mpeg')\n",
        " \n",
        "        vout = cv2.VideoWriter()\n",
        "        vout.open(os.path.join(\"videos\", \"res\", video), fourcc, 20, sz, True)\n",
        "    \n",
        "        while True:\n",
        "            res, frame = camera.read()\n",
        "    \n",
        "            if not res:\n",
        "                break\n",
        "  \n",
        "            image = detect_image(frame, yolo, all_classes)\n",
        "            cv2.imshow(\"detection\", image)\n",
        "  \n",
        "            # Save the video frame by frame\n",
        "            vout.write(image)\n",
        "    \n",
        "            if cv2.waitKey(110) & 0xff == 27:\n",
        "                    break\n",
        "  \n",
        "        vout.release()  \n",
        "        camera.release()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKSgYi_6XmAr",
        "outputId": "fde48e0c-ce7c-4d9a-c8f8-e845de8681f8"
      },
      "source": [
        "yolo = YOLO(0.6,0.5)\n",
        "file = 'data/coco_classes.txt'\n",
        "all_classes = get_classes(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c97s-5qYLql"
      },
      "source": [
        "***Detecting Images***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhtaApigYRvL",
        "outputId": "0bf420ae-a4d0-41b1-e175-5e9b11c97795"
      },
      "source": [
        "f = 'images/photo1.jpg'\n",
        "image = cv2.imread(f)\n",
        "image = detect_image(image, yolo, all_classes)\n",
        "cv2.imwrite('images/res/photo1_detected.jpg',image)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 31.14s\n",
            "class: person, score: 0.99\n",
            "box coordinate x,y,w,h: [203.84439826  66.64711142 100.21853447 210.87221336]\n",
            "class: person, score: 0.88\n",
            "box coordinate x,y,w,h: [422.88118601  86.06504011  53.96313965 148.27685761]\n",
            "class: person, score: 0.70\n",
            "box coordinate x,y,w,h: [387.61651516  80.25743079  52.08951235 160.3105607 ]\n",
            "class: car, score: 1.00\n",
            "box coordinate x,y,w,h: [ -6.70309365  89.40106821 216.0769105  138.94352341]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKKMT6dubE-d"
      },
      "source": [
        "***Detect Video***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EKxoVu0bIAM"
      },
      "source": [
        "## detect video one at a time in videos/test folder\n",
        "# video = 'library1.mp4'\n",
        "#detect_video(video,yolo, all_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI-eyWk4hNkx"
      },
      "source": [
        "# ***Open Camera***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuSe_MYXg4PJ"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMJHTAteg4PQ"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvC97t-0hbGK"
      },
      "source": [
        "# **CapStone Project**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAiYD7t2hkIT"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import pairwise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYcPLo2pjegd"
      },
      "source": [
        "background = None\n",
        "\n",
        "accumulated_weight = 0.5\n",
        "\n",
        "roi_top = 20\n",
        "roi_bottom = 300\n",
        "roi_right = 300\n",
        "roi_left = 600\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VklN2meWjyFy"
      },
      "source": [
        "def calc_accum_avg(frame,accumulated_weight):\n",
        "\n",
        "  global background\n",
        "\n",
        "  if background is none:\n",
        "    background = frame.copy().astype('float')\n",
        "    return None\n",
        "  \n",
        "  cv2.accumulateWeighted(frame,background,accumulated_weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH8qeo51k4H0"
      },
      "source": [
        "def segment(frame,threshold=25):\n",
        "\n",
        "  diff = cv2.absdiff(background.astype('uint8'),frame)\n",
        "\n",
        "  ret,thresholded = cv2.threshold(diff,threshold_min,255,cv2.THRESH_BINARY)\n",
        "\n",
        "  image,contours,hierarchy = cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  if len(contours) == 0:\n",
        "    return None\n",
        "\n",
        "  else:\n",
        "     hand_segment = max(contours,key=cv2.contourArea)\n",
        "\n",
        "     return(thresholded,hand_segment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIqhycVnmTSp"
      },
      "source": [
        "def count_fingers(thresholded,hand_segment):\n",
        "\n",
        "  conv_hull =cv2.convexHull(hand_segment)\n",
        "\n",
        "  top = tuple(conv_hull[conv_hull[:,:,1].argmin()[0]])\n",
        "  bottom = tuple(conv_hull[conv_hull[:,:,1].argmax()[0]])\n",
        "  left = tuple(conv_hull[conv_hull[:,:,0].argmin()[0]])\n",
        "  right = tuple(conv_hull[conv_hull[:,:,0].argmax()[0]])\n",
        "\n",
        "  cX = (left[0] + right[0]) // 2\n",
        "  cY = (top[1] + bottom[1]) // 2\n",
        "\n",
        "  distance = pairwase.euclidean_distances([cX,cY], Y=[left,right,top,bottom])[0]\n",
        "\n",
        "  max_distance = distance.max()\n",
        "\n",
        "  radius = int(0.9*max_distancce)\n",
        "  circumfrence = (2*np.pi*radius)\n",
        "\n",
        "  circular_roi = np.zeros(thresholded[:,2],dtype='uint8')\n",
        "\n",
        "  cv2.circle(circular_roi,(cX,cY),radius,255,10)\n",
        "\n",
        "  circular_roi = cv2.bitwise_and(thresholded, thresholded, mask=circular_roi)\n",
        "\n",
        "  image, contours, hierarchy = cv2.findContours(circular_roi.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  for cnt in contours:\n",
        " \n",
        "          (x, y, w, h) = cv2.boundingRect(cnt)\n",
        "  \n",
        "          out_of_wrist = ((cY + (cY * 0.25)) > (y + h))\n",
        "          # 2. Number of points along the contour does not exceed 25% of the circumference of the circular ROI (otherwise we're counting points off the hand)\\n\",\n",
        "          limit_points = ((circumference * 0.25) > cnt.shape[0]) \n",
        "           \n",
        "          if  out_of_wrist and limit_points:\n",
        "                count += 1\n",
        "    \n",
        "  return count\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "zPIIUZwXs_Vr",
        "outputId": "9303a31a-74d9-42b9-eea5-2d53ba3f1b0c"
      },
      "source": [
        "#cam = cv2.VideoCapture(0)\n",
        "\n",
        "num_frames = 0\n",
        "\n",
        "while True:\n",
        "   \n",
        "        ret, frame = cam.read()\n",
        "  \n",
        "        frame = cv2.flip(frame, 1)\n",
        "    \n",
        "        frame_copy = frame.copy()\n",
        "   \n",
        "        gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "\n",
        "        if num_frames < 60:\n",
        "           calc_accum_avg(gray, accumulated_weight)\n",
        "\n",
        "           if num_frames <= 59:\n",
        "                cv2.putText(frame_copy, \"WAIT! GETTING BACKGROUND AVG.\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "                cv2.imshow(\"Finger Count\",frame_copy)\n",
        "        else:\n",
        "            hand = segment(gray)\n",
        "  \n",
        "            if hand is not None:\n",
        "\n",
        "                thresholded, hand_segment = hand\n",
        "  \n",
        "                cv2.drawContours(frame_copy, [hand_segment + (roi_right, roi_top)], -1, (255, 0, 0),1)\n",
        " \n",
        "                fingers = count_fingers(thresholded, hand_segment)\n",
        "  \n",
        "                cv2.putText(frame_copy, str(fingers), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "                cv2.imshow(\"Thesholded\", thresholded)\n",
        "\n",
        "\n",
        "        cv2.rectangle(frame_copy, (roi_left, roi_top), (roi_right, roi_bottom), (0,0,255), 5)\n",
        "        num_frames += 1\n",
        "\n",
        "        cv2.imshow(\"Finger Count\", frame_copy)\n",
        "\n",
        "        k = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "        if k == 27:\n",
        "            break\n",
        "\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-60f57b13acc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mframe_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
          ]
        }
      ]
    }
  ]
}